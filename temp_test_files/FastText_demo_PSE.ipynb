{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fa81428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import sklearn.ensemble\n",
    "\n",
    "import fasttext\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f51e993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df1 = pd.read_excel('../../Downloads/CHEME DIRECT/NLP Project/PSE Dataset.xlsx', sheet_name='SamePerson Report')\n",
    "df2 = pd.read_excel('../../Downloads/CHEME DIRECT/NLP Project/PSE Dataset.xlsx', sheet_name='Multiple People Report')\n",
    "df3 = pd.read_excel('../../Downloads/CHEME DIRECT/NLP Project/PSE Dataset.xlsx', sheet_name='Multiple People Less Details')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "960a4dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1, test_1 = sklearn.model_selection.train_test_split(df1, test_size=0.2, random_state=206)\n",
    "train_2, test_2 = sklearn.model_selection.train_test_split(df2, test_size=0.2, random_state=206)\n",
    "train_3, test_3 = sklearn.model_selection.train_test_split(df3, test_size=0.2, random_state=206)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ebc1ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1_text = train_1['Report'].values.reshape(-1,1)\n",
    "test_1_text = test_1['Report'].values.reshape(-1,1)\n",
    "\n",
    "train_1_label = train_1['Level'].values.reshape(-1,1)\n",
    "test_1_label = test_1['Level'].values.reshape(-1,1)\n",
    "\n",
    "train_2_text = train_2['Report'].values.reshape(-1,1)\n",
    "test_2_text = test_2['Report'].values.reshape(-1,1)\n",
    "\n",
    "train_2_label = train_2['Level'].values.reshape(-1,1)\n",
    "test_2_label = test_2['Level'].values.reshape(-1,1)\n",
    "\n",
    "train_3_text = train_3['Report'].values.reshape(-1,1)\n",
    "test_3_text = test_3['Report'].values.reshape(-1,1)\n",
    "\n",
    "train_3_label = train_3['Level'].values.reshape(-1,1)\n",
    "test_3_label = test_3['Level'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13d298d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2_text_list = train_2_text.tolist()\n",
    "train_2_text_str = [item for sublist in train_2_text_list for item in sublist]\n",
    "\n",
    "test_2_text_list = test_2_text.tolist()\n",
    "test_2_text_str = [item for sublist in test_2_text_list for item in sublist]\n",
    "\n",
    "train_2_label_list = train_2_label.tolist()\n",
    "train_2_label_str = [item for sublist in train_2_label_list for item in sublist]\n",
    "\n",
    "test_2_label_list = test_2_label.tolist()\n",
    "test_2_label_str = [item for sublist in test_2_label_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "613f6c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "with open('train.txt', 'w') as f:\n",
    "    for text, label in zip(train_2_text_str, train_2_label_str):\n",
    "        f.write(f'__label__{label} {text}\\n')\n",
    "\n",
    "with open('test.txt', 'w') as f:\n",
    "    for text, label in zip(test_2_text_str, test_2_label_str):\n",
    "        f.write(f'__label__{label} {text}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c92838f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Read 0M words\n",
      "Number of words:  342\n",
      "Number of labels: 5\n",
      "\r",
      "Progress: 102.3% words/sec/thread:   39433 lr: -0.002324 avg.loss:  1.613351 ETA:   0h 0m 0s\r",
      "Progress: 100.0% words/sec/thread:   39352 lr:  0.000000 avg.loss:  1.613351 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "model = fasttext.train_supervised('train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98280ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t20\n",
      "P@1\t0.450\n",
      "R@1\t0.450\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('test.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d214615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.27      0.67      0.38         6\n",
      "           4       0.00      0.00      0.00         6\n",
      "           5       0.75      0.50      0.60         6\n",
      "\n",
      "    accuracy                           0.35        20\n",
      "   macro avg       0.20      0.23      0.20        20\n",
      "weighted avg       0.30      0.35      0.29        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jlonging/miniconda3/envs/nlpmaps/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Jlonging/miniconda3/envs/nlpmaps/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Jlonging/miniconda3/envs/nlpmaps/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Jlonging/miniconda3/envs/nlpmaps/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Jlonging/miniconda3/envs/nlpmaps/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Jlonging/miniconda3/envs/nlpmaps/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Predict labels for test data\n",
    "pred_labels = []\n",
    "true_labels = test_1_label_str\n",
    "\n",
    "for text in test_1_text_str:\n",
    "    pred = model.predict(text)\n",
    "    pred_label = int(pred[0][0].replace('__label__', ''))\n",
    "    pred_labels.append(pred_label)\n",
    "    \n",
    "# Generate classification report\n",
    "print(sklearn.metrics.classification_report(true_labels, pred_labels, target_names=['1', '2', '3', '4', '5']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1620f760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
