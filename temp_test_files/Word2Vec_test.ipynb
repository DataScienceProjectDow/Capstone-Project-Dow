{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # provide sql-like data manipulation tools. very handy.\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np # high dimensional vector computing library.\n",
    "from copy import deepcopy\n",
    "from string import punctuation\n",
    "from random import shuffle\n",
    "\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec # the word2vec model gensim class\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer # a tweet tokenizer from nltk.\n",
    "tokenizer = TweetTokenizer()\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>On April 10th at 12:30 PM, there was an incide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>On April 8th at 9:00 PM, a fire broke out in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>On April 6th at 2:45 AM, there was an incident...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>On April 5th at 7:15 PM, there was an unplanne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>On April 2nd at 11:30 AM, there was a minor in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>3</td>\n",
       "      <td>At 9:45 AM, a worker reported a small leak of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>5</td>\n",
       "      <td>At 2:30 PM, a worker reported a small spill of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>4</td>\n",
       "      <td>At 6:15 AM, a worker reported an unusual odor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2</td>\n",
       "      <td>At 11:00 AM, a worker reported a small fire in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1</td>\n",
       "      <td>At 4:00 PM, an unplanned event occurred in the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Level                                             Report\n",
       "0        2  On April 10th at 12:30 PM, there was an incide...\n",
       "1        3  On April 8th at 9:00 PM, a fire broke out in t...\n",
       "2        4  On April 6th at 2:45 AM, there was an incident...\n",
       "3        1  On April 5th at 7:15 PM, there was an unplanne...\n",
       "4        5  On April 2nd at 11:30 AM, there was a minor in...\n",
       "..     ...                                                ...\n",
       "295      3  At 9:45 AM, a worker reported a small leak of ...\n",
       "296      5  At 2:30 PM, a worker reported a small spill of...\n",
       "297      4  At 6:15 AM, a worker reported an unusual odor ...\n",
       "298      2  At 11:00 AM, a worker reported a small fire in...\n",
       "299      1  At 4:00 PM, an unplanned event occurred in the...\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data = pd.read_csv('/Users/andrewsimon/Desktop/Dow_dat.csv')\n",
    "main_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(report):\n",
    "    try:\n",
    "        tokens = tokenizer.tokenize(report)\n",
    "        return tokens\n",
    "    except:\n",
    "        return \"NC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(data):\n",
    "    data['tokens'] = data['Report'].progress_map(tokenize)\n",
    "    data = data[data.tokens != 'NC']\n",
    "    data.reset_index(inplace=True)\n",
    "    data.drop('index', inplace=True, axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data = postprocess(main_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Report</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>On April 10th at 12:30 PM, there was an incide...</td>\n",
       "      <td>[on, april, th, at, pm, there, was, an, incide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>On April 8th at 9:00 PM, a fire broke out in t...</td>\n",
       "      <td>[on, april, th, at, pm, fire, broke, out, in, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>On April 6th at 2:45 AM, there was an incident...</td>\n",
       "      <td>[on, april, th, at, am, there, was, an, incide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>On April 5th at 7:15 PM, there was an unplanne...</td>\n",
       "      <td>[on, april, th, at, pm, there, was, an, unplan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>On April 2nd at 11:30 AM, there was a minor in...</td>\n",
       "      <td>[on, april, nd, at, am, there, was, minor, inc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Level                                             Report  \\\n",
       "0      2  On April 10th at 12:30 PM, there was an incide...   \n",
       "1      3  On April 8th at 9:00 PM, a fire broke out in t...   \n",
       "2      4  On April 6th at 2:45 AM, there was an incident...   \n",
       "3      1  On April 5th at 7:15 PM, there was an unplanne...   \n",
       "4      5  On April 2nd at 11:30 AM, there was a minor in...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [on, april, th, at, pm, there, was, an, incide...  \n",
       "1  [on, april, th, at, pm, fire, broke, out, in, ...  \n",
       "2  [on, april, th, at, am, there, was, an, incide...  \n",
       "3  [on, april, th, at, pm, there, was, an, unplan...  \n",
       "4  [on, april, nd, at, am, there, was, minor, inc...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data['tokens'] = main_data['Report'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "main_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>Report</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>On April 10th at 12:30 PM, there was an incide...</td>\n",
       "      <td>[on, april, th, at, pm, there, was, an, incide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>On April 8th at 9:00 PM, a fire broke out in t...</td>\n",
       "      <td>[on, april, th, at, pm, fire, broke, out, in, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>On April 6th at 2:45 AM, there was an incident...</td>\n",
       "      <td>[on, april, th, at, am, there, was, an, incide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>On April 5th at 7:15 PM, there was an unplanne...</td>\n",
       "      <td>[on, april, th, at, pm, there, was, an, unplan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>On April 2nd at 11:30 AM, there was a minor in...</td>\n",
       "      <td>[on, april, nd, at, am, there, was, minor, inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>3</td>\n",
       "      <td>At 9:45 AM, a worker reported a small leak of ...</td>\n",
       "      <td>[at, am, worker, reported, small, leak, of, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>5</td>\n",
       "      <td>At 2:30 PM, a worker reported a small spill of...</td>\n",
       "      <td>[at, pm, worker, reported, small, spill, of, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>4</td>\n",
       "      <td>At 6:15 AM, a worker reported an unusual odor ...</td>\n",
       "      <td>[at, am, worker, reported, an, unusual, odor, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2</td>\n",
       "      <td>At 11:00 AM, a worker reported a small fire in...</td>\n",
       "      <td>[at, am, worker, reported, small, fire, in, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1</td>\n",
       "      <td>At 4:00 PM, an unplanned event occurred in the...</td>\n",
       "      <td>[at, pm, an, unplanned, event, occurred, in, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Level                                             Report  \\\n",
       "0        2  On April 10th at 12:30 PM, there was an incide...   \n",
       "1        3  On April 8th at 9:00 PM, a fire broke out in t...   \n",
       "2        4  On April 6th at 2:45 AM, there was an incident...   \n",
       "3        1  On April 5th at 7:15 PM, there was an unplanne...   \n",
       "4        5  On April 2nd at 11:30 AM, there was a minor in...   \n",
       "..     ...                                                ...   \n",
       "295      3  At 9:45 AM, a worker reported a small leak of ...   \n",
       "296      5  At 2:30 PM, a worker reported a small spill of...   \n",
       "297      4  At 6:15 AM, a worker reported an unusual odor ...   \n",
       "298      2  At 11:00 AM, a worker reported a small fire in...   \n",
       "299      1  At 4:00 PM, an unplanned event occurred in the...   \n",
       "\n",
       "                                                tokens  \n",
       "0    [on, april, th, at, pm, there, was, an, incide...  \n",
       "1    [on, april, th, at, pm, fire, broke, out, in, ...  \n",
       "2    [on, april, th, at, am, there, was, an, incide...  \n",
       "3    [on, april, th, at, pm, there, was, an, unplan...  \n",
       "4    [on, april, nd, at, am, there, was, minor, inc...  \n",
       "..                                                 ...  \n",
       "295  [at, am, worker, reported, small, leak, of, ch...  \n",
       "296  [at, pm, worker, reported, small, spill, of, c...  \n",
       "297  [at, am, worker, reported, an, unusual, odor, ...  \n",
       "298  [at, am, worker, reported, small, fire, in, th...  \n",
       "299  [at, pm, an, unplanned, event, occurred, in, t...  \n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(main_data.tokens),\n",
    "                                                    np.array(main_data.Level), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "240it [00:00, 1142602.68it/s]\n",
      "60it [00:00, 299593.14it/s]\n"
     ]
    }
   ],
   "source": [
    "def labelizeReports(reports, label_type):\n",
    "    labelized = []\n",
    "    for i,v in tqdm(enumerate(reports)):\n",
    "        label = '%s_%s'%(label_type,i)\n",
    "        labelized.append(TaggedDocument(v, [label]))\n",
    "    return labelized\n",
    "\n",
    "X_train = labelizeReports(X_train, 'TRAIN')\n",
    "X_test = labelizeReports(X_test, 'TEST')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['at', 'am', 'worker', 'reported', 'an', 'issue', 'with', 'the', 'reaction', 'unit', 'temperature', 'control', 'system', 'the', 'issue', 'was', 'resolved', 'by', 'adjusting', 'the', 'system', 'settings', 'no', 'injuries', 'or', 'environmental', 'impacts', 'were', 'reported'], tags=['TRAIN_0'])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 240/240 [00:00<00:00, 1691820.10it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 240/240 [00:00<00:00, 3322220.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32651, 75600)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_w2v = Word2Vec(vector_size=200, min_count=10)\n",
    "tweet_w2v.build_vocab([x.words for x in tqdm(X_train)])\n",
    "tweet_w2v.train([x.words for x in tqdm(X_train)], total_examples=tweet_w2v.corpus_count, epochs=tweet_w2v.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewsimon/Library/Python/3.8/lib/python/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer=lambda x: x, min_df=10)\n",
    "matrix = vectorizer.fit_transform([x.words for x in X_train])\n",
    "tfidf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildWordVector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += tweet_w2v.wv.get_vector(word).reshape((1, size)) * tfidf[word]\n",
    "            count += 1.\n",
    "        except KeyError: # handling the case where the token is not\n",
    "                         # in the corpus. useful for testing.\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "240it [00:00, 7070.00it/s]\n",
      "60it [00:00, 7155.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "train_vecs_w2v = np.concatenate([buildWordVector(z, 200) for z in tqdm(map(lambda x: x.words, X_train))])\n",
    "train_vecs_w2v = scale(train_vecs_w2v)\n",
    "\n",
    "test_vecs_w2v = np.concatenate([buildWordVector(z, 200) for z in tqdm(map(lambda x: x.words, X_test))])\n",
    "test_vecs_w2v = scale(test_vecs_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 1, 3, 5, 5, 3, 1, 4, 5, 5, 2, 5, 3, 5, 1, 5, 2, 3, 4, 3, 3,\n",
       "       3, 3, 3, 4, 1, 3, 3, 3, 2, 2, 2, 5, 2, 5, 4, 1, 5, 1, 5, 4, 1, 2,\n",
       "       1, 1, 2, 4, 1, 4, 1, 5, 2, 5, 5, 3, 1, 4, 3, 4, 4, 2, 5, 2, 4, 3,\n",
       "       4, 3, 4, 1, 4, 5, 3, 5, 5, 2, 5, 3, 3, 5, 2, 2, 2, 2, 2, 1, 3, 3,\n",
       "       5, 4, 5, 4, 1, 5, 4, 4, 1, 5, 4, 5, 2, 1, 3, 3, 2, 4, 4, 4, 2, 3,\n",
       "       3, 2, 2, 3, 1, 2, 5, 1, 2, 3, 5, 4, 1, 4, 1, 1, 3, 3, 2, 1, 3, 1,\n",
       "       2, 2, 3, 2, 2, 3, 5, 3, 2, 1, 3, 2, 5, 2, 2, 4, 1, 2, 5, 5, 5, 4,\n",
       "       4, 5, 5, 2, 3, 5, 5, 4, 5, 3, 3, 1, 4, 4, 5, 2, 3, 5, 3, 4, 5, 4,\n",
       "       1, 3, 1, 1, 5, 5, 5, 5, 4, 4, 1, 4, 3, 4, 3, 3, 5, 2, 5, 4, 4, 4,\n",
       "       5, 2, 2, 1, 4, 2, 4, 2, 3, 5, 1, 2, 4, 1, 4, 4, 1, 4, 3, 3, 1, 4,\n",
       "       2, 5, 5, 5, 2, 4, 4, 5, 5, 5, 5, 4, 4, 2, 5, 5, 2, 3, 4, 4])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "8/8 - 0s - loss: -7.4800e+00 - accuracy: 0.1500 - 170ms/epoch - 21ms/step\n",
      "Epoch 2/9\n",
      "8/8 - 0s - loss: -1.7134e+01 - accuracy: 0.1500 - 5ms/epoch - 619us/step\n",
      "Epoch 3/9\n",
      "8/8 - 0s - loss: -2.5574e+01 - accuracy: 0.1500 - 6ms/epoch - 695us/step\n",
      "Epoch 4/9\n",
      "8/8 - 0s - loss: -3.3885e+01 - accuracy: 0.1500 - 5ms/epoch - 595us/step\n",
      "Epoch 5/9\n",
      "8/8 - 0s - loss: -4.2512e+01 - accuracy: 0.1500 - 7ms/epoch - 818us/step\n",
      "Epoch 6/9\n",
      "8/8 - 0s - loss: -5.1405e+01 - accuracy: 0.1500 - 10ms/epoch - 1ms/step\n",
      "Epoch 7/9\n",
      "8/8 - 0s - loss: -6.1064e+01 - accuracy: 0.1500 - 7ms/epoch - 839us/step\n",
      "Epoch 8/9\n",
      "8/8 - 0s - loss: -7.1258e+01 - accuracy: 0.1500 - 5ms/epoch - 635us/step\n",
      "Epoch 9/9\n",
      "8/8 - 0s - loss: -8.2007e+01 - accuracy: 0.1500 - 5ms/epoch - 647us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x290702c40>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(32, activation='relu', input_dim=200))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_vecs_w2v, y_train, epochs=9, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
