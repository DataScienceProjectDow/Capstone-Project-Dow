{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a64d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from gensim.models.fasttext import load_facebook_model\n",
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.ensemble\n",
    "import sklearn\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b6c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FastText model\n",
    "fasttext_model = load_facebook_vectors('../../Downloads/CHEME DIRECT/NLP Project/cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d81c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class for embedding\n",
    "class FastTextVectorizer:\n",
    "    def __init__(self, fasttext_model):\n",
    "        self.fasttext_model = fasttext_model\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.fasttext_model[w] for w in words.split() if w in self.fasttext_model]\n",
    "                    or [np.zeros(self.fasttext_model.vector_size)], axis=0)\n",
    "            for words in X\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857ef2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df1 = pd.read_excel('../../Downloads/CHEME DIRECT/NLP Project/PSE Dataset.xlsx', sheet_name='SamePerson Report')\n",
    "df2 = pd.read_excel('../../Downloads/CHEME DIRECT/NLP Project/PSE Dataset.xlsx', sheet_name='Multiple People Report')\n",
    "df3 = pd.read_excel('../../Downloads/CHEME DIRECT/NLP Project/PSE Dataset.xlsx', sheet_name='Multiple People Less Details')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdc311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing dataset\n",
    "dev_1, test_1 = sklearn.model_selection.train_test_split(df1, test_size=0.2, random_state=26)\n",
    "dev_2, test_2 = sklearn.model_selection.train_test_split(df2, test_size=0.2, random_state=26)\n",
    "dev_3, test_3 = sklearn.model_selection.train_test_split(df3, test_size=0.2, random_state=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1efdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get text and label from each dataset\n",
    "dev_1_text = dev_1['Report'].values.reshape(-1,1)\n",
    "test_1_text = test_1['Report'].values.reshape(-1,1)\n",
    "\n",
    "dev_1_label = dev_1['Level'].values.reshape(-1,1)\n",
    "test_1_label = test_1['Level'].values.reshape(-1,1)\n",
    "\n",
    "dev_2_text = dev_2['Report'].values.reshape(-1,1)\n",
    "test_2_text = test_2['Report'].values.reshape(-1,1)\n",
    "\n",
    "dev_2_label = dev_2['Level'].values.reshape(-1,1)\n",
    "test_2_label = test_2['Level'].values.reshape(-1,1)\n",
    "\n",
    "dev_3_text = dev_3['Report'].values.reshape(-1,1)\n",
    "test_3_text = test_3['Report'].values.reshape(-1,1)\n",
    "\n",
    "dev_3_label = dev_3['Level'].values.reshape(-1,1)\n",
    "test_3_label = test_3['Level'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa5a3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert texts and labels into format of list\n",
    "def to_list(data):\n",
    "    list_of_list = data.tolist()\n",
    "    new_data = [item for sublist in list_of_list for item in sublist]\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f2df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to lists\n",
    "dev_1_text_str = to_list(dev_1_text)\n",
    "dev_1_label_str = to_list(dev_1_label)\n",
    "\n",
    "dev_2_text_str = to_list(dev_2_text)\n",
    "dev_2_label_str = to_list(dev_2_label)\n",
    "\n",
    "dev_3_text_str = to_list(dev_3_text)\n",
    "dev_3_label_str = to_list(dev_3_label)\n",
    "\n",
    "test_1_text_str = to_list(test_1_text)\n",
    "test_1_label_str = to_list(test_1_label)\n",
    "\n",
    "test_2_text_str = to_list(test_2_text)\n",
    "test_2_label_str = to_list(test_2_label)\n",
    "\n",
    "test_3_text_str = to_list(test_3_text)\n",
    "test_3_label_str = to_list(test_3_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7608f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate three sets together\n",
    "dev_text = dev_1_text_str + dev_2_text_str + dev_3_text_str\n",
    "test_text = test_1_text_str + test_2_text_str + test_3_text_str\n",
    "\n",
    "dev_label = dev_1_label_str + dev_2_label_str + dev_3_label_str\n",
    "test_label = test_1_label_str + test_2_label_str + test_3_label_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8331298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform raw text data to vectors\n",
    "vectorizer = FastTextVectorizer(fasttext_model)\n",
    "dev_text_ft = vectorizer.transform(dev_text)\n",
    "test_text_ft = vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54f6573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training set to have a validation set\n",
    "train_x, val_x, train_y, val_y = sklearn.model_selection.train_test_split(\n",
    "    dev_text_ft, dev_label, test_size=0.2, random_state=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100de17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization using Optuna\n",
    "def train_evaluate_hyperparameters(n_estimators, max_depth, min_weight_fraction_leaf):\n",
    "    # create model\n",
    "    model = sklearn.ensemble.RandomForestClassifier(\n",
    "        n_estimators=n_estimators, max_depth=max_depth, min_weight_fraction_leaf=min_weight_fraction_leaf)\n",
    "    # train the model on the training set\n",
    "    model.fit(train_x, train_y)\n",
    "    # evaluate the model on the validation set\n",
    "    score = model.score(val_x, val_y)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38c8621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # define hyperparameter space\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 5000)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 600)\n",
    "    min_weight_fraction_leaf = trial.suggest_uniform(\n",
    "        'min_weight_fraction_leaf', 0.0, 0.5)\n",
    "    \n",
    "    # get the score for the hyperparameters chosen\n",
    "    score = train_evaluate_hyperparameters(n_estimators, max_depth, min_weight_fraction_leaf)\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(sampler=optuna.samplers.TPESampler(), direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "print('Best params: ', study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc281e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest model\n",
    "model = sklearn.ensemble.RandomForestClassifier(\n",
    "    n_estimators=871, min_weight_fraction_leaf=0.001978389039761175, max_depth=472)\n",
    "\n",
    "model.fit(dev_text_ft, dev_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810c3877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy report\n",
    "print(\"model accuracy:\", model.score(test_text_ft, test_label))\n",
    "\n",
    "predict_label = model.predict(test_text_ft)\n",
    "\n",
    "print(sklearn.metrics.classification_report(test_label, predict_label, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cab270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a confusion matrix\n",
    "sklearn.metrics.ConfusionMatrixDisplay.from_estimator(clf, test_text_ft, test_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
