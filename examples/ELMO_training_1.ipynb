{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import tensorflow.keras.layers \n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Dropout\n",
    ")\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data = pd.read_csv('/Users/andrewsimon/Desktop/IMDBDataset.csv.zip')\n",
    "main_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      One of the other reviewers has mentioned that ...          1\n",
       "1      A wonderful little production. <br /><br />The...          1\n",
       "2      I thought this was a wonderful way to spend ti...          1\n",
       "3      Basically there's a family where a little boy ...          0\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...          1\n",
       "...                                                  ...        ...\n",
       "49995  I thought this movie did a down right good job...          1\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...          0\n",
       "49997  I am a Catholic taught in parochial elementary...          0\n",
       "49998  I'm going to have to disagree with the previou...          0\n",
       "49999  No one expects the Star Trek movies to be high...          0\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data['sentiment'] = main_data['sentiment'].map({'positive':1, 'negative': 0})\n",
    "main_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = main_data['review'].tolist()\n",
    "train_text = [' '.join(t.split()[0:150]) for t in train_text]\n",
    "train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
    "train_label = main_data['sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_text, train_label, test_size=0.2, random_state=1516)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElmoEmbeddingLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.dimensions = 1024\n",
    "        self.trainable = True\n",
    "        super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.elmo = hub.Module('https://tfhub.dev/google/elmo/3', trainable=self.trainable,\n",
    "                               name=\"{}_module\".format(self.name))\n",
    "        super(ElmoEmbeddingLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        result = self.elmo(\n",
    "            K.squeeze(K.cast(x, tf.string), axis=1),\n",
    "            as_dict=True,\n",
    "            signature='default',\n",
    "            )['default']\n",
    "        return result\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return K.not_equal(inputs, '--PAD--')\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/andrewsimon/Library/Python/3.8/lib/python/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 262,657\n",
      "Trainable params: 262,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_text = tensorflow.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
    "embedding = ElmoEmbeddingLayer()(input_text)\n",
    "dense = tensorflow.keras.layers.Dense(256, activation='relu')(embedding)\n",
    "pred = tensorflow.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_3/Sigmoid:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/andrewsimon/nlpmaps/examples/ELMO_training_1.ipynb Cell 9\u001b[0m in \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andrewsimon/nlpmaps/examples/ELMO_training_1.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m learnRate \u001b[39m=\u001b[39m \u001b[39m0.001\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andrewsimon/nlpmaps/examples/ELMO_training_1.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m input_text \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,), dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstring\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minput_0\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/andrewsimon/nlpmaps/examples/ELMO_training_1.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m x \u001b[39m=\u001b[39m ElmoEmbeddingLayer(trainable\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)(input_text)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andrewsimon/nlpmaps/examples/ELMO_training_1.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m x \u001b[39m=\u001b[39m Dropout(\u001b[39m0.3\u001b[39m)(x)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/andrewsimon/nlpmaps/examples/ELMO_training_1.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m x \u001b[39m=\u001b[39m Dense(\u001b[39m256\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m)(x)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:784\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    782\u001b[0m   \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m    783\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[0;32m--> 784\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(cast_inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    786\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOperatorNotAllowedInGraphError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    787\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mYou are attempting to use Python control \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    788\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mflow in a layer that was not declared to be \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    789\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mdynamic. Pass `dynamic=True` to the class \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    790\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mconstructor.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mEncountered error:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m\n\u001b[1;32m    791\u001b[0m                   \u001b[39mstr\u001b[39m(e) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/8f/mjj28lvs5fb1m_c_tvmtckl80000gn/T/__autograph_generated_filech4pv82q.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m result \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49melmo, (ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(K)\u001b[39m.\u001b[39;49msqueeze, (ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(K)\u001b[39m.\u001b[39;49mcast, (ag__\u001b[39m.\u001b[39;49mld(x), ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mstring), \u001b[39mNone\u001b[39;49;00m, fscope),), \u001b[39mdict\u001b[39;49m(axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m), fscope),), \u001b[39mdict\u001b[39;49m(as_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, signature\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdefault\u001b[39;49m\u001b[39m'\u001b[39;49m), fscope)[\u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/8f/mjj28lvs5fb1m_c_tvmtckl80000gn/T/__autograph_generated_file8o4tar_f.py:32\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf____call__\u001b[0;34m(self, inputs, _sentinel, signature, as_dict)\u001b[0m\n\u001b[1;32m     30\u001b[0m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(_check_supported_types), (ag__\u001b[39m.\u001b[39mld(output_tensor_infos), ag__\u001b[39m.\u001b[39mld(signature), \u001b[39m'\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m'\u001b[39m), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     31\u001b[0m dict_inputs \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(_convert_dict_inputs), (ag__\u001b[39m.\u001b[39mld(inputs), ag__\u001b[39m.\u001b[39mld(input_tensor_infos)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 32\u001b[0m dict_outputs \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_impl\u001b[39m.\u001b[39;49mcreate_apply_graph, (), \u001b[39mdict\u001b[39;49m(signature\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(signature), input_tensors\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(dict_inputs), name\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(name)), fscope)\n\u001b[1;32m     33\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/8f/mjj28lvs5fb1m_c_tvmtckl80000gn/T/__autograph_generated_file4bcvca9o.py:120\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__create_apply_graph\u001b[0;34m(self, signature, input_tensors, name)\u001b[0m\n\u001b[1;32m    118\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mand_((\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mlen\u001b[39m), (ag__\u001b[39m.\u001b[39mld(meta_graph)\u001b[39m.\u001b[39mcollection_def,), \u001b[39mNone\u001b[39;00m, fscope)), (\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(_is_tpu_graph_function), (), \u001b[39mNone\u001b[39;00m, fscope))), if_body_4, else_body_4, get_state_6, set_state_6, (), \u001b[39m0\u001b[39m)\n\u001b[1;32m    119\u001b[0m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mimport_meta_graph, (ag__\u001b[39m.\u001b[39mld(meta_graph),), \u001b[39mdict\u001b[39m(input_map\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(feed_map), import_scope\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(relative_scope_name)), fscope)\n\u001b[0;32m--> 120\u001b[0m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(fix_colocation_after_import), (), \u001b[39mdict\u001b[39;49m(input_map\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(feed_map), absolute_import_scope\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(absolute_scope_name)), fscope)\n\u001b[1;32m    122\u001b[0m \u001b[39m@ag__\u001b[39m\u001b[39m.\u001b[39mautograph_artifact\n\u001b[1;32m    123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_tensor\u001b[39m(name):\n\u001b[1;32m    124\u001b[0m     \u001b[39mwith\u001b[39;00m ag__\u001b[39m.\u001b[39mFunctionScope(\u001b[39m'\u001b[39m\u001b[39mget_tensor\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfscope_1\u001b[39m\u001b[39m'\u001b[39m, ag__\u001b[39m.\u001b[39mSTD) \u001b[39mas\u001b[39;00m fscope_1:\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/8f/mjj28lvs5fb1m_c_tvmtckl80000gn/T/__autograph_generated_filepv7rpit8.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__fix_colocation_after_import\u001b[0;34m(input_map, absolute_import_scope)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mwith\u001b[39;00m ag__\u001b[39m.\u001b[39mFunctionScope(\u001b[39m'\u001b[39m\u001b[39mfix_colocation_after_import\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfscope\u001b[39m\u001b[39m'\u001b[39m, ag__\u001b[39m.\u001b[39mSTD) \u001b[39mas\u001b[39;00m fscope:\n\u001b[1;32m      9\u001b[0m     attr_map \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(_build_colocation_attr_map), (ag__\u001b[39m.\u001b[39mld(input_map), ag__\u001b[39m.\u001b[39mld(absolute_import_scope)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 10\u001b[0m     ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(_apply_colocation_attr_map), (ag__\u001b[39m.\u001b[39;49mld(attr_map), ag__\u001b[39m.\u001b[39;49mld(absolute_import_scope)), \u001b[39mNone\u001b[39;49;00m, fscope)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/autograph/impl/api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args)\n\u001b[1;32m    442\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "File \u001b[0;32m/var/folders/8f/mjj28lvs5fb1m_c_tvmtckl80000gn/T/__autograph_generated_filet1_fk9f8.py:176\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf___apply_colocation_attr_map\u001b[0;34m(colocation_attr_map, absolute_import_scope)\u001b[0m\n\u001b[1;32m    174\u001b[0m new_coloc_group \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39mnew_coloc_group\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    175\u001b[0m class_value \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39mclass_value\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 176\u001b[0m ag__\u001b[39m.\u001b[39;49mfor_stmt(ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(graph)\u001b[39m.\u001b[39;49mget_operations, (), \u001b[39mNone\u001b[39;49;00m, fscope), \u001b[39mNone\u001b[39;49;00m, loop_body_2, get_state_9, set_state_9, (), {\u001b[39m'\u001b[39;49m\u001b[39miterate_names\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mop\u001b[39;49m\u001b[39m'\u001b[39;49m})\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/autograph/operators/control_flow.py:451\u001b[0m, in \u001b[0;36mfor_stmt\u001b[0;34m(iter_, extra_test, body, get_state, set_state, symbol_names, opts)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(iter_, distribute\u001b[39m.\u001b[39mIterable):\n\u001b[1;32m    448\u001b[0m   \u001b[39m# TODO(b/162250181): Use _tf_iterator_for_stmt(iter(iter_)...\u001b[39;00m\n\u001b[1;32m    449\u001b[0m   for_fn \u001b[39m=\u001b[39m _tf_distributed_iterable_for_stmt\n\u001b[0;32m--> 451\u001b[0m for_fn(iter_, extra_test, body, get_state, set_state, symbol_names, opts)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/autograph/operators/control_flow.py:502\u001b[0m, in \u001b[0;36m_py_for_stmt\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    501\u001b[0m   \u001b[39mfor\u001b[39;00m target \u001b[39min\u001b[39;00m iter_:\n\u001b[0;32m--> 502\u001b[0m     body(target)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/autograph/operators/control_flow.py:469\u001b[0m, in \u001b[0;36m_py_for_stmt.<locals>.protected_body\u001b[0;34m(protected_iter)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprotected_body\u001b[39m(protected_iter):\n\u001b[1;32m    468\u001b[0m   original_body(protected_iter)\n\u001b[0;32m--> 469\u001b[0m   after_iteration()\n\u001b[1;32m    470\u001b[0m   before_iteration()\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/autograph/operators/control_flow.py:872\u001b[0m, in \u001b[0;36m_PythonLoopChecker.after_iteration\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    869\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_unroll_limits()\n\u001b[1;32m    871\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_op_count_after_iteration:\n\u001b[0;32m--> 872\u001b[0m   did_warn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_verify_inefficient_unroll()\n\u001b[1;32m    873\u001b[0m   \u001b[39mif\u001b[39;00m did_warn:\n\u001b[1;32m    874\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop_checking_inefficient_unroll()  \u001b[39m# Only warn once.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/autograph/operators/control_flow.py:839\u001b[0m, in \u001b[0;36m_PythonLoopChecker._verify_inefficient_unroll\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mops_before_iteration \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    838\u001b[0m ops_after_iteration \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_ops()\n\u001b[0;32m--> 839\u001b[0m new_ops \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39;49m(\n\u001b[1;32m    840\u001b[0m     op \u001b[39mfor\u001b[39;49;00m op \u001b[39min\u001b[39;49;00m ops_after_iteration \u001b[39mif\u001b[39;49;00m op \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mops_before_iteration)\n\u001b[1;32m    842\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(new_ops) \u001b[39m<\u001b[39m INEFFICIENT_UNROLL_MIN_OPS:\n\u001b[1;32m    843\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/autograph/operators/control_flow.py:840\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mops_before_iteration \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    838\u001b[0m ops_after_iteration \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_ops()\n\u001b[1;32m    839\u001b[0m new_ops \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\n\u001b[0;32m--> 840\u001b[0m     op \u001b[39mfor\u001b[39;00m op \u001b[39min\u001b[39;00m ops_after_iteration \u001b[39mif\u001b[39;00m op \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mops_before_iteration)\n\u001b[1;32m    842\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(new_ops) \u001b[39m<\u001b[39m INEFFICIENT_UNROLL_MIN_OPS:\n\u001b[1;32m    843\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_classes = 1\n",
    "batch_size = 512\n",
    "epochs = 200\n",
    "learnRate = 0.001\n",
    "\n",
    "input_text = tf.keras.Input(shape=(1,), dtype=\"string\", name='input_0')\n",
    "x = ElmoEmbeddingLayer(trainable=False)(input_text)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(num_classes, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs=[input_text], outputs=x)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 'binary_crossentropy'\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "tf.compat.v1.InteractiveSession()\n",
    "tf.compat.v1.Session().run(tf.compat.v1.global_variables_initializer())\n",
    "tf.compat.v1.Session().run(tf.compat.v1.tables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.InteractiveSession()\n",
    "tf.compat.v1.Session().run(tf.compat.v1.global_variables_initializer())\n",
    "tf.compat.v1.Session().run(tf.compat.v1.tables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 22:47:01.039477: W tensorflow/c/c_api.cc:300] Operation '{name:'dense_3/bias/Assign' id:7913 op device:{requested: '', assigned: ''} def:{{{node dense_3/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](dense_3/bias, dense_3/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-05-03 22:47:01.187335: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at resource_variable_ops.cc:678 : NOT_FOUND: Resource localhost/elmo_embedding_layer_1_module/bilm/char_embed/N10tensorflow3VarE does not exist.\n",
      "2023-05-03 22:47:01.187367: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at resource_variable_ops.cc:678 : NOT_FOUND: Resource localhost/elmo_embedding_layer_1_module/bilm/char_embed/N10tensorflow3VarE does not exist.\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Could not find variable elmo_embedding_layer_1_module/bilm/CNN/b_cnn_4. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status error message=Resource localhost/elmo_embedding_layer_1_module/bilm/CNN/b_cnn_4/N10tensorflow3VarE does not exist.\n\t [[{{node elmo_embedding_layer_1/elmo_embedding_layer_1_module_apply_default/bilm/CNN_2/add_4/ReadVariableOp}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/andrewsimon/nlpmaps/examples/ELMO_training_1.ipynb Cell 11\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/andrewsimon/nlpmaps/examples/ELMO_training_1.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test), epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/engine/training_v1.py:856\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_call_args(\u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    855\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_training_loop(x)\n\u001b[0;32m--> 856\u001b[0m \u001b[39mreturn\u001b[39;00m func\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    857\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    858\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m    859\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    860\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    861\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    862\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    863\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    864\u001b[0m     validation_split\u001b[39m=\u001b[39;49mvalidation_split,\n\u001b[1;32m    865\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m    866\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m    867\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m    868\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    869\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[1;32m    870\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m    871\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m    872\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[1;32m    873\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m    874\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m    875\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m    876\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/engine/training_arrays_v1.py:734\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.fit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    729\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`validation_steps` should not be specified if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    730\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`validation_data` is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    731\u001b[0m         )\n\u001b[1;32m    732\u001b[0m     val_x, val_y, val_sample_weights \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m \u001b[39mreturn\u001b[39;00m fit_loop(\n\u001b[1;32m    735\u001b[0m     model,\n\u001b[1;32m    736\u001b[0m     inputs\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m    737\u001b[0m     targets\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    738\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weights,\n\u001b[1;32m    739\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    740\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    741\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    742\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    743\u001b[0m     val_inputs\u001b[39m=\u001b[39;49mval_x,\n\u001b[1;32m    744\u001b[0m     val_targets\u001b[39m=\u001b[39;49mval_y,\n\u001b[1;32m    745\u001b[0m     val_sample_weights\u001b[39m=\u001b[39;49mval_sample_weights,\n\u001b[1;32m    746\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m    747\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[1;32m    748\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m    749\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m    750\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[1;32m    751\u001b[0m     steps_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msteps_per_epoch\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    752\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/engine/training_arrays_v1.py:421\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m callbacks\u001b[39m.\u001b[39m_call_batch_hook(\n\u001b[1;32m    417\u001b[0m     mode, \u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m, batch_index, batch_logs\n\u001b[1;32m    418\u001b[0m )\n\u001b[1;32m    420\u001b[0m \u001b[39m# Get outputs.\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m batch_outs \u001b[39m=\u001b[39m f(ins_batch)\n\u001b[1;32m    422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(batch_outs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    423\u001b[0m     batch_outs \u001b[39m=\u001b[39m [batch_outs]\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/backend.py:4608\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4598\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   4599\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callable_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   4600\u001b[0m     \u001b[39mor\u001b[39;00m feed_arrays \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_feed_arrays\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4604\u001b[0m     \u001b[39mor\u001b[39;00m session \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_session\n\u001b[1;32m   4605\u001b[0m ):\n\u001b[1;32m   4606\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[0;32m-> 4608\u001b[0m fetched \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_callable_fn(\u001b[39m*\u001b[39;49marray_vals, run_metadata\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_metadata)\n\u001b[1;32m   4609\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fetches) :])\n\u001b[1;32m   4610\u001b[0m output_structure \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mpack_sequence_as(\n\u001b[1;32m   4611\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs_structure,\n\u001b[1;32m   4612\u001b[0m     fetched[: \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs)],\n\u001b[1;32m   4613\u001b[0m     expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   4614\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/client/session.py:1481\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1479\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1480\u001b[0m   run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1481\u001b[0m   ret \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39;49mTF_SessionRunCallable(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session\u001b[39m.\u001b[39;49m_session,\n\u001b[1;32m   1482\u001b[0m                                          \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle, args,\n\u001b[1;32m   1483\u001b[0m                                          run_metadata_ptr)\n\u001b[1;32m   1484\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[1;32m   1485\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Could not find variable elmo_embedding_layer_1_module/bilm/CNN/b_cnn_4. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status error message=Resource localhost/elmo_embedding_layer_1_module/bilm/CNN/b_cnn_4/N10tensorflow3VarE does not exist.\n\t [[{{node elmo_embedding_layer_1/elmo_embedding_layer_1_module_apply_default/bilm/CNN_2/add_4/ReadVariableOp}}]]"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
