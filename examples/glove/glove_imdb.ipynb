{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f3ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import zipfile\n",
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import sklearn.ensemble\n",
    "import sklearn.linear_model\n",
    "\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7837a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pre-trained GloVe vectors from the website\n",
    "URL = 'https://nlp.stanford.edu/data/glove.6B.zip'\n",
    "FILE_NAME = 'glove.6B.zip'\n",
    "urllib.request.urlretrieve(URL, FILE_NAME)\n",
    "\n",
    "with zipfile.ZipFile(FILE_NAME, 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "\n",
    "# Transfer pre-trained GloVe vectors into word2vec format\n",
    "GLOVE_FILE = 'glove.6B.100d.txt'\n",
    "WORD2VEC_FILE = GLOVE_FILE + '.word2vec'\n",
    "glove2word2vec(GLOVE_FILE, WORD2VEC_FILE)\n",
    "\n",
    "# Load pre-trained GloVe vectors\n",
    "glove_model = KeyedVectors.load_word2vec_format(WORD2VEC_FILE, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbe380a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load IMDB dataset\n",
    "df = load_dataset('imdb')\n",
    "\n",
    "train_text = df['train']['text']\n",
    "train_label = df['train']['label']\n",
    "\n",
    "test_text = df['test']['text']\n",
    "test_label = df['test']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2467c87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for tokenizing the text data\n",
    "class Word2VecVectorizer:\n",
    "    def __init__(self, model_vec):\n",
    "        print(\"Loading in word vectors...\")\n",
    "        self.word_vectors = model_vec\n",
    "        print(\"Finished loading in word vectors\")\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"fit data\"\"\"\n",
    "\n",
    "    def transform(self, data):\n",
    "        \"\"\"determine the dimensionality of vectors\"\"\"\n",
    "        v_get = self.word_vectors.get_vector('king')\n",
    "        self.D = v_get.shape[0]\n",
    "\n",
    "        x_vec = np.zeros((len(data), self.D))\n",
    "        n_count = 0\n",
    "        emptycount = 0\n",
    "\n",
    "        for sentence in data:\n",
    "            tokens = sentence.split()\n",
    "            vecs = []\n",
    "            m_count = 0\n",
    "            for word in tokens:\n",
    "                try:\n",
    "                    # throws KeyError if word not found\n",
    "                    vec = self.word_vectors.get_vector(word)\n",
    "                    vecs.append(vec)\n",
    "                    m_count += 1\n",
    "                except KeyError:\n",
    "                    pass\n",
    "\n",
    "            if len(vecs) > 0:\n",
    "                vecs = np.array(vecs)\n",
    "                x_vec[n_count] = vecs.mean(axis=0)\n",
    "            else:\n",
    "                emptycount += 1\n",
    "            n_count += 1\n",
    "\n",
    "        print(\"Numer of samples with no words found: %s / %s\" % (emptycount,\n",
    "        \tlen(data)))\n",
    "        return x_vec\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        \"\"\"transform the strings to vectors\"\"\"\n",
    "        self.fit(data)\n",
    "\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ceaf5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set a word vectorizer\n",
    "vectorizer = Word2VecVectorizer(glove_model)\n",
    "\n",
    "# Get the sentence embeddings for the train dataset\n",
    "train_x = vectorizer.fit_transform(train_text)\n",
    "train_y = train_label\n",
    "\n",
    "# Get the sentence embeddings for the test dataset\n",
    "test_x = vectorizer.transform(test_text)\n",
    "test_y = test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66cd6e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train a Random Forest model\n",
    "model = sklearn.linear_model.RidgeClassifier(alpha=2)\n",
    "\n",
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d255ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy report\n",
    "print(\"model accuracy:\", model.score(test_x, test_y))\n",
    "\n",
    "predict_y = model.predict(test_x)\n",
    "\n",
    "print(sklearn.metrics.classification_report(test_y, predict_y, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c9e90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a confusion matrix\n",
    "sklearn.metrics.ConfusionMatrixDisplay.from_estimator(model, test_x, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
